# ETL-Pipelines

RealTime Data Pipeline

To set up the Realtime data pipeline, follow these steps:
1) Install & setup All The tools Such as Kafka,MYSQL,Pyspark,ElasticSearch.
2) Create a Kafka Topic 
3) Create a producer and push data  to Topic created Run Kafka locally and Use Producer.py file for data ingesting of data
4) Create Consumer using Consumer.py. Subscribe to Topic created before. And check if it receives a data
5) Create a database.And Create a schema For Storing data.
6) Use Sql.connect file and make changes accordingly.
7) Now Start Pyspark engine. Push data on Pyspark
8) Perform aggregations and Process data.
9) Finally Use Elastic Searchto Effeciently search data. 
